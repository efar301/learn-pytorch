{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epnwKp8zDOzk"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Colab link [here](https://colab.research.google.com/drive/1-jRsXmrcgku8POGf5Dp_-J_CjjkANX17?usp=sharing)\n",
        "\n",
        "Now that you have a model, you should test how well it was trained. This is where `scikit-learn`, a popular python ml library comes into play.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMkFYokZOF38"
      },
      "source": [
        "***\n",
        "# Quick Aside\n",
        "\n",
        "In previous lessons, you may have seen me use `model.train()` or `model.eval()` and wondered what these meant. Here's where I finally explain them.\n",
        "\n",
        "`.train()` puts the model into training mode. It is typically used before starting the training loop. Train mode makes sure that dropout and batch normalization are working as intended.\n",
        "\n",
        "`.eval()` disables any regularization. It should be used before any validation or inference. It disables dropout layers and uses learned statistics from batch normalization. Normally, you use `.eval()` in tandem with `torch.no_grad()`.\n",
        "\n",
        "`torch.no_grad()` disables gradient calculations. This makes calculations quicker and use less memory. Its more efficient to use for validation and inference. It is used with the `with` context management keyword, like this: `with torch.no_grad():`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxlhIUOODlDw"
      },
      "source": [
        "***\n",
        "# Validation\n",
        "\n",
        "The first type of evaluation you can do is actually during training, and this is validation. When we train a model, we want to make sure that it doesn't memorize (overfit) to the training data. We want to avoid overfitting because it means a model won't be able to generalize it's learned information to a problem it may see when deployed.\n",
        "\n",
        "<br>\n",
        "\n",
        "Validation is normally implemented by splitting a dataset into three partitions: train, validation and test. Normally, we use an 80 10 10 or a 70 20 10 split.\n",
        "\n",
        "<br>\n",
        "\n",
        "During training, We will spend an epoch on the training dataset and calculate the loss. In the same epoch, the model will also test itself on the validation data to see how well the model is generalizing.\n",
        "\n",
        "<br>\n",
        "\n",
        "It is important to note that the model will never train on the validation data. It is purely meant to see how well the model is learning. If training loss continually decreases but validation loss increases, it means your model is memorizing the training data and not learning to generalize to unseen data. \n",
        "\n",
        "<br>\n",
        "\n",
        "Let's check out a training loop with a validation implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqMWGvAs8zsV"
      },
      "outputs": [],
      "source": [
        "# import necessary modules\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "model = fakeModel()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss = 0\n",
        "  validation_loss = 0\n",
        "\n",
        "  model.train()\n",
        "  for batch in train_dataloader:\n",
        "    inputs, targets = batch\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # compute loss\n",
        "    batch_loss = loss(outputs, targets)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    batch_loss.backward()\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # sum up loss for this epoch\n",
        "    train_loss += batch_loss.item()\n",
        "\n",
        "  # switch model to evaluation mode\n",
        "  model.eval()\n",
        "  # we dont need gradients since we're not training\n",
        "  with torch.no_grad():\n",
        "    for batch in validation_dataloader:\n",
        "      inputs, targets = batch\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      batch_loss = loss(outputs, targets)\n",
        "\n",
        "      validation_loss += batch_loss.item()\n",
        "\n",
        "      # no backward pass or updating parameters needed\n",
        "\n",
        "  # get average loss for an epoch\n",
        "  avg_train_loss = train_loss / len(train_dataloader)\n",
        "  avg_validation_loss = validation_loss / len(validation_dataloader)\n",
        "\n",
        "  print(f'Epoch {epoch + 1} / {num_epochs} | Training Loss: {avg_train_loss:.4f} | Validation Loss: {avg_validation_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kshTEXOiYAu4"
      },
      "source": [
        "***\n",
        "# Types of ML Problems\n",
        "\n",
        "There are two main types of problems in machine learning, classification and regression.\n",
        "\n",
        "<br>\n",
        "\n",
        "Classification problems are when a model sorts an input into a bucket. An example is the MNIST dataset, where we are sorting inputs into their corresponding numbers.\n",
        "\n",
        "Regression problems are the opposite of classification. They involve predicting continuous values. An example of this could be predicting the number of calories someone would burn during a workout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMVUvV66X8c7"
      },
      "source": [
        "***\n",
        "# Classification Metrics\n",
        "\n",
        "Classification and Regression problems have different metrics. Some common classification methods include:\n",
        "1. Accuracy\n",
        "2. Precision\n",
        "3. Recall\n",
        "4. F1 Score\n",
        "\n",
        "<br>\n",
        "\n",
        "Accuracy is the number of correct labels divided by the total number of samples. This can be misleading when we have unequal class sizes (i.e. one class has 10x more samples than another class).\n",
        "\n",
        "The formula is `TP / TOTAL` where TP is true positives.\n",
        "\n",
        "<br>\n",
        "\n",
        "Precision is calculated as the number of true positives divided by the sum of true and false positives. It calculates the true positive rate. Higher is better.\n",
        "\n",
        "The formula is `TP / (TP + FP)`\n",
        "\n",
        "<br>\n",
        "\n",
        "Recall takes all the positive samples, and calculates how many the model correctly classified. Higher is better.\n",
        "\n",
        "The formula is `TP / (TP + FN)`\n",
        "\n",
        "<br>\n",
        "\n",
        "F1 Score is a harmonic mean of precision and recall. Higher is better.\n",
        "\n",
        "The formula is `2 * (Precision * Recall) / (Precision * Recall)`\n",
        "\n",
        "<br>\n",
        "\n",
        "## Summary\n",
        "\n",
        "Never just use one statistic. Combining multiple allows you see a better picture of your model's performance. Here are some general trends to look out for.\n",
        "\n",
        "<br>\n",
        "\n",
        "High precision, High recall -> The model is cautious in its predictions and misses true positives\n",
        "\n",
        "Low precision, high recall -> The model predicts many true positives but also many false positives.\n",
        "\n",
        "<br>\n",
        "\n",
        "Let's see some examples on implementation below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dp4P_27oVh1"
      },
      "outputs": [],
      "source": [
        "# import necessary modules\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# example predictions\n",
        "y_true = [0, 1, 1, 0, 1, 0, 1, 1]\n",
        "y_pred = [0, 1, 0, 0, 1, 1, 1, 0]\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "print(f'Precision: {precision:.2f}')\n",
        "\n",
        "recall = recall_score(y_true, y_pred)\n",
        "print(f'Recall: {recall:.2f}')\n",
        "\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "print(f'F1 Score: {f1:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COoyjfIwMr9W"
      },
      "source": [
        "***\n",
        "# Regression Metrics\n",
        "\n",
        "Regression metrics are a bit easier to understand initially. Let's tackle some basic ones.\n",
        "\n",
        "1. Mean Squared Error\n",
        "2. Mean Absolute Error\n",
        "\n",
        "<br>\n",
        "\n",
        "Mean Squared Error is the squared distance between the actual and predicted values. It punishes outliers heavily due to the distance being squared. Lower is better.\n",
        "\n",
        "$$\n",
        "\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "Mean Absolute Error is the absolute distance between the actual and predicted value. It doesn't punish outliers as harshly as MSE. Lower is better.\n",
        "\n",
        "$$\n",
        "\\frac{1}{n} \\sum_{i=1}^n \\left| y_i - \\hat{y}_i \\right|\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "Let's see some examples on implementation below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hUu7ZN6oWRu"
      },
      "outputs": [],
      "source": [
        "# import necessary modules\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# example predictions\n",
        "y_true = [3.0, -0.5, 2.0, 7.0]\n",
        "y_pred = [2.5, 0.0, 2.1, 7.8]\n",
        "\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "print(f'MSE: {mse:.2f}')\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "print(f'MAE: {mae:.2f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
