{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o3Sel_EJzyF"
      },
      "source": [
        "\n",
        "# Pytorch Basics\n",
        "#### Today, we're going to learn about the basic pytorch operations that are used in data handling and model creation.\n",
        "\n",
        "Colab link [here](https://colab.research.google.com/drive/1-Aq91EMnrDQDxnsfeORuN0KeKDyAQt1Q?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZB2Hs9sdJdx"
      },
      "outputs": [],
      "source": [
        "#import necessary module\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKGsMWdQKP7F"
      },
      "source": [
        "# Tensors and tensor properties\n",
        "\n",
        "Tensors are matricies that have n dimensions. This can be confusing at first but its easy to get the hang of it once we see a few examples.\n",
        "\n",
        "Let's start by creating a tensor. There are several functions that allow us to do that.\n",
        "\n",
        "\n",
        "*   `torch.tensor()`\n",
        "*   `torch.zeros()`\n",
        "*   `torch.ones()`\n",
        "*   `torch.randn()`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bObEM49Jjk_"
      },
      "outputs": [],
      "source": [
        "# creating a tensor can be done multiple ways\n",
        "\n",
        "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "tensor2 = torch.zeros(4, 2)\n",
        "\n",
        "tensor3 = torch.ones(1, 3)\n",
        "\n",
        "tensor4 = torch.randn(2, 2, 2)\n",
        "\n",
        "# can you tell what these tensors look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV2HXInse9Hn",
        "outputId": "520f0739-d794-4ae3-c7d9-7fd8ec669a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]]) \n",
            "\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]]) \n",
            "\n",
            "tensor([[1., 1., 1.]]) \n",
            "\n",
            "tensor([[[ 0.1264,  0.2294],\n",
            "         [-0.9029,  1.5924]],\n",
            "\n",
            "        [[ 1.7528, -2.5850],\n",
            "         [ 0.7688,  0.5188]]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run this cell to check if your guesses are correct\n",
        "\n",
        "print(tensor1, '\\n')\n",
        "print(tensor2, '\\n')\n",
        "print(tensor3, '\\n')\n",
        "print(tensor4, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since these tensors may be hard to understand, let's see a visual example. Images can be turned into tensors. A standard RGB image has 3 color channels and each pixel can have a value [0-255]. We can turn each color channel into a 2D matrix of RGB values. Three of these 2D matricies is a 3D tensor which stores all of the information in the image so that a model can learn to process it.\n",
        "\n",
        "\n",
        "<img src='../images/image_tensor.png' width=50% height=50%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3tuqWg5hQPJ"
      },
      "source": [
        "# Tensor Properties\n",
        "\n",
        "Now that we've learned to create tensors, let's learn how to get the properties of tensors we create.\n",
        "\n",
        "\n",
        "Tensors have several properties, the ones this tutorial will cover are:\n",
        "\n",
        "*   `dtype`\n",
        "*   `shape`\n",
        "*   `device`\n",
        "*   `ndim`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI2wMNglmGMS",
        "outputId": "784b3a99-3a46-4f91-ca29-30f31eee9820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.int64 \n",
            "\n",
            "torch.Size([3, 3]) \n",
            "\n",
            "cpu \n",
            "\n",
            "2 \n",
            "\n",
            "\n",
            "\n",
            "torch.float32 \n",
            "\n",
            "torch.Size([2, 2, 2]) \n",
            "\n",
            "cpu \n",
            "\n",
            "3 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# run this cell to see the results\n",
        "\n",
        "print(tensor1.dtype, '\\n')\n",
        "print(tensor1.shape, '\\n')\n",
        "print(tensor1.device, '\\n')\n",
        "print(tensor1.ndim, '\\n')\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "print(tensor4.dtype, '\\n')\n",
        "print(tensor4.shape, '\\n')\n",
        "print(tensor4.device, '\\n')\n",
        "print(tensor4.ndim, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPiHWpYAp3W0"
      },
      "source": [
        "Let's break down the values we just got.\n",
        "\n",
        "<br>\n",
        "\n",
        "tensor1.dtype returned int64. This means each value in the tensor is of type int64.\n",
        "\n",
        "The shape was [3, 3]. When we created the tensor, we created it with 3 lists consisting of three values each.\n",
        "\n",
        "Cpu is the device the tensor is loaded on. The cpu is generally where data types are initially created and then transferred to other devices.\n",
        "\n",
        "Finally, ndim is 2. The tensor is two dimensional.\n",
        "\n",
        "<br>\n",
        "\n",
        "Now, try to understand why the shape of tensor4 is [2, 2, 2], the dtype is float64 and why ndim is 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv_T3Fefspb6"
      },
      "source": [
        "# Tensor Operations\n",
        "\n",
        "Finally, the fun stuff. Let's see how we can manipulate tensors with mathematical operations.\n",
        "\n",
        "<br>\n",
        "\n",
        "We can use standard python operators to do elementwise operations. Note that tensors must be of the same size.\n",
        "\n",
        "*   `+` &nbsp; &nbsp; &nbsp; addition\n",
        "*   `-` &nbsp; &nbsp; &nbsp; subtraction\n",
        "*   `*` &nbsp; &nbsp; &nbsp; multiplication\n",
        "*   `/` &nbsp; &nbsp; &nbsp; division\n",
        "*   `**` &nbsp; &nbsp; squaring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR3MUKKcspMZ",
        "outputId": "919eed07-eabf-42db-b435-c93ab55b3a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.]])\n",
            "\n",
            "\n",
            "tensor([[0., 0., -0.],\n",
            "        [0., 0., 0.],\n",
            "        [-0., -0., 0.]])\n",
            "\n",
            "\n",
            "tensor([[   nan, 0.8837,    nan],\n",
            "        [   nan,    nan,    nan]])\n",
            "\n",
            "tensor([[2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.]])\n"
          ]
        }
      ],
      "source": [
        "# let's start with an easy example\n",
        "tensor1 = torch.ones(2, 2)\n",
        "tensor2 = torch.ones(2, 2)\n",
        "\n",
        "print(tensor1 + tensor2)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "# take a wild guess with this one\n",
        "tensor3 = torch.randn(3, 3)\n",
        "tensor4 = torch.zeros(3, 3)\n",
        "\n",
        "print(tensor3 * tensor4)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "# let's do a harder one\n",
        "tensor5 = torch.randn(2, 3)\n",
        "tensor6 = torch.randn(2, 3)\n",
        "\n",
        "print(tensor5 ** tensor6) # this may lead to some unexpected results\n",
        "print()\n",
        "\n",
        "# curveball\n",
        "tensor7 = torch.ones(4, 4)\n",
        "print(tensor7 * 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqBDIvBt2Oiy"
      },
      "source": [
        "Tensors also take advantage of logical operators. Let's see a quick example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4K2s4wr6r9Hj"
      },
      "outputs": [],
      "source": [
        "# before you run this code cell, guess what the output will be\n",
        "\n",
        "print(tensor5 >= tensor6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ7AhhE94If6"
      },
      "source": [
        "# Linear algebra\n",
        "\n",
        "The power of tensors comes from the linear algebra, we can perform various linear algebra operations to manipulate them to our needs.\n",
        "\n",
        "*  `torch.matmul(), @` &nbsp; &nbsp; &nbsp; matrix multiplication\n",
        "*  `.transpose(), .T` &nbsp; &nbsp; &nbsp; matrix transposition\n",
        "*  `torch.eye()` &nbsp; &nbsp; &nbsp; 2D identity tensor\n",
        "* `torch.dot()` &nbsp; &nbsp; &nbsp; dot product between two 1D tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWNpgycg-zG6",
        "outputId": "b2368038-5902-4d22-fc48-a9ea67872edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[19, 22],\n",
            "        [43, 50]])\n",
            "\n",
            "\n",
            "tensor([[19, 22],\n",
            "        [43, 50]])\n",
            "\n",
            "\n",
            "tensor([[ 1,  5,  9, 13],\n",
            "        [ 2,  6, 10, 14],\n",
            "        [ 3,  7, 11, 15],\n",
            "        [ 4,  8, 12, 16]])\n",
            "\n",
            "\n",
            "tensor([[ 1,  5,  9, 13],\n",
            "        [ 2,  6, 10, 14],\n",
            "        [ 3,  7, 11, 15],\n",
            "        [ 4,  8, 12, 16]])\n",
            "\n",
            "\n",
            "tensor(0.8440)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# these are a bit more complicated\n",
        "# if you need to review matrix multiplication rules this is a good resource\n",
        "# https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
        "\n",
        "\n",
        "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor2 = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "tensor3 = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])\n",
        "\n",
        "# @ implicitly calls torch.matmul()\n",
        "print(tensor1 @ tensor2)\n",
        "print('\\n')\n",
        "print(torch.matmul(tensor1, tensor2))\n",
        "print('\\n')\n",
        "\n",
        "# remember transposition rules\n",
        "print(tensor3.transpose(0, 1)) # choose specific dimensions to transpose (mainly used with CNNs)\n",
        "print('\\n')\n",
        "print(tensor3.T) # .T implicitly calls .transpose(-2, -1)\n",
        "print('\\n')\n",
        "\n",
        "# how many dimensions will this last tensor have? how can you check?\n",
        "tensor3 = torch.randn(3)\n",
        "tensor4 = torch.randn(3)\n",
        "print(torch.dot(tensor3, tensor4))\n",
        "print('\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YOaET45KhYe"
      },
      "source": [
        "Tensor Reshaping\n",
        "\n",
        "Transposing isn't the only way to reshape a matrix. Pytorch provides other functions for higher dimensional tensors. Let's check them out.\n",
        "\n",
        "*  `.view()`\n",
        "*  `.reshape()`\n",
        "*  `.squeeze()`\n",
        "*  `.unsqueeze()`\n",
        "*  `.permute()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAhnQJdiL2Qr",
        "outputId": "c82c8716-babd-44ac-cb29-eb1f2f0f8792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before .view()\n",
            "torch.Size([3, 3])\n",
            "\n",
            "\n",
            "After .view()\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "torch.Size([9])\n",
            "\n",
            "\n",
            "Before .reshape()\n",
            "torch.Size([3, 3])\n",
            "\n",
            "\n",
            "Afer .reshape()\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "torch.Size([9])\n",
            "\n",
            "\n",
            "torch.Size([1, 3, 1, 5])\n",
            "torch.Size([3, 5])\n",
            "torch.Size([1, 3, 5])\n",
            "\n",
            "\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 1, 3])\n",
            "torch.Size([1, 2, 3])\n",
            "\n",
            "\n",
            "torch.Size([2, 3, 4])\n",
            "torch.Size([2, 4, 3])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# .view() reshapes a tensor from the original dimensions to a new specified one\n",
        "tensor1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8 ,9]])\n",
        "print('Before .view()')\n",
        "print(tensor1.shape)\n",
        "print('\\n')\n",
        "print('After .view()')\n",
        "print(tensor1.view(9))\n",
        "print(tensor1.view(9).shape) # what do you notice?\n",
        "print('\\n')\n",
        "\n",
        "# .reshape() is almost the same as .view but it is more leniant on what can be reshaped\n",
        "tensor2 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8 ,9]])\n",
        "print('Before .reshape()')\n",
        "print(tensor1.shape)\n",
        "print('\\n')\n",
        "print('Afer .reshape()')\n",
        "print(tensor1.reshape(9))\n",
        "print(tensor1.reshape(9).shape) # what do you notice?\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "# .squeeze() may be confusing at first, but take a look at the output\n",
        "tensor3 = torch.ones(1, 3, 1, 5)\n",
        "print(tensor3.shape)\n",
        "print(tensor3.squeeze().shape) # what happened to the tensor after it was squeezed?\n",
        "print(tensor3.squeeze(2).shape) # what about here?\n",
        "print('\\n')\n",
        "\n",
        "# .unsqueeze() is the opposite of .squeeze()\n",
        "tensor4 = torch.ones(2, 3)\n",
        "print(tensor4.shape)\n",
        "print(tensor4.unsqueeze(1).shape) # what changed?\n",
        "print(tensor4.unsqueeze(0).shape)\n",
        "print('\\n')\n",
        "\n",
        "# .permute reorders dimensions, its a more powerful transpose\n",
        "tensor5 = torch.randn(2, 3, 4)\n",
        "print(tensor5.shape)\n",
        "print('.permute(0, 2, 1)')\n",
        "print(tensor5.permute(0, 2, 1).shape)\n",
        "print('.permute(0, -2, -1)')\n",
        "print(tensor5.permute(0, -2, -1).shape) # notice anything strange? what do negative numbers mean? Think string slicing...\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
