{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f07ff6",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "When we look at an object, how do we know what we are looking at? Our brain detects edges, curves and patterns before piecing them together into something we know. A CNN does the same thing, early layers detect simple features in an image before deeper layers combine them into more complex shapes, recognizing the image. \n",
    "\n",
    "### Convolutions\n",
    "\n",
    "A convolution is a mathematical operation that combines two functions into a new, third function. Our input image can be considered one function, and our second function is a matrix of weights called a kernel. By sliding the kernel over the image, we can create a third function, known as a feature map of the input image.\n",
    "\n",
    "<img src=\"../images/convolution.png\" \n",
    "        alt=\"Picture\" \n",
    "        style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "Kernel weights are learnable parameters that are updated through backpropagation. This means that the model learns what features are important. We don't have to manually choose the features.\n",
    "\n",
    "### Properties\n",
    "\n",
    "The parameters of a convolution in pytorch are:\n",
    "- Input Channels: the number of input channels into the convolution\n",
    "- Output Channels: the number of channels to output after the convolution, multiple output channels means one kernel per channel\n",
    "- Kernel Size: the shape of the kernel, generally square\n",
    "- Stride: how far to \"step\" between one kernel and the next\n",
    "- Padding: how much larger to make the input image\n",
    "### Output Size\n",
    "\n",
    "The output size of the image is dependent on the parameters of the convolution.\n",
    "\n",
    "$$\n",
    "\\text{Output Size} = \\frac{\\text{Input Size} - \\text{Kernel Size} + 2 \\times \\text{Padding}}{\\text{Stride}} + 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7407d",
   "metadata": {},
   "source": [
    "***\n",
    "# Pooling\n",
    "\n",
    "Another staple of CNNs is pooling. It is a downsampling step where a window is slid over pixels to compress the width and height of an image. The number of channels is preserved. Pooling is normally used after a convolution + activation.\n",
    "\n",
    "Pooling is not a learnable layer in a CNN.\n",
    "\n",
    "There are several forms of pooling:\n",
    "- Min: keeping the minimum value of the window\n",
    "- Max: keeping the maximum value of the window\n",
    "- Average: taking the average of the window\n",
    "\n",
    "<img src=\"../images/pooling.png\" \n",
    "        alt=\"Picture\" \n",
    "        height=400\n",
    "        width=500\n",
    "        style=\"display: block; margin: 0 auto\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f585e2e",
   "metadata": {},
   "source": [
    "***\n",
    "# Example\n",
    "\n",
    "An example CNN can be found [here](../test-models/cnn/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
