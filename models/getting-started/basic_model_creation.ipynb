{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0d_JChE-a_l"
      },
      "source": [
        "# Model Creation\n",
        "\n",
        "This is probably what you've been waiting for. The real meat and potatoes of machine learning. Let's learn how to build a model with pytorch.\n",
        "\n",
        "<br>\n",
        "\n",
        "Models in pytorch are built from the `nn.Module` class. They must have a `__init__()` and `forward()` method. I will create a very basic fully connected model below.\n",
        "\n",
        "Colab link [here](https://colab.research.google.com/drive/1W14vnDRtv7kyBvTlkuBr5C3FJ8NkToDR?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DOOS__16-ao8"
      },
      "outputs": [],
      "source": [
        "# import necessary modules\n",
        "import torch\n",
        "import torch.nn as nn # layers\n",
        "import torch.nn.functional as F # activation functions\n",
        "\n",
        "class BasicModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(10, 5)\n",
        "    self.layer2 = nn.Linear(5, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.layer2(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gZBAnrmB7r6"
      },
      "source": [
        "The model above consists of two layers as seen in the `__init__()` function. `nn.Linear(x, y)` is a fully connected layer with x inputs and y outputs. Sequential layers must have their inputs/outputs aligned.\n",
        "\n",
        "<br>\n",
        "\n",
        "The `forward()` function defines how information passes through a model. We pass `x` into the model, the raw input. From there, `x` is transformed by layer1, passed tthorugh the relu activation function and then transformed by layer2 before finally being returned.\n",
        "\n",
        "<br>\n",
        "\n",
        "Lets test the model and see the output from calling it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67RCKycU-Zfv",
        "outputId": "0b2dc80c-a64c-4413-ed3b-d072e190c532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BasicModel(\n",
            "  (layer1): Linear(in_features=10, out_features=5, bias=True)\n",
            "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
            ") \n",
            "\n",
            "tensor([[-0.0266],\n",
            "        [-0.2941]], grad_fn=<AddmmBackward0>) \n",
            "\n",
            "torch.Size([2, 1]) \n",
            "\n",
            "Number of parameters: 61\n"
          ]
        }
      ],
      "source": [
        "# initialize the model\n",
        "model = BasicModel()\n",
        "\n",
        "# printing the model allows us to see its structure\n",
        "print(model, '\\n')\n",
        "\n",
        "# create a fake tensor of the expected input size (10)\n",
        "input = torch.randn(2, 10) # (batch_size, values)\n",
        "\n",
        "output = model(input) # calling model() implicitly calls forward\n",
        "print(output, '\\n')\n",
        "print(output.shape, '\\n')\n",
        "\n",
        "# we can count trainable parameters like this\n",
        "print(\"Number of parameters:\", sum(p.numel() for p in model.parameters()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDuLvxf6FKSo"
      },
      "source": [
        "Notice how the output tensor has two values? Our model makes a computation for each sample in the batch. In this case, we provided 2 samples with 10 input features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiuLEH_3H4dR",
        "outputId": "a654809c-aa01-4f43-93ab-dac979bbca9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mat1 and mat2 shapes cannot be multiplied (2x9 and 10x5)\n"
          ]
        }
      ],
      "source": [
        "# calling the model with a wrong input shape yields errors\n",
        "try:\n",
        "  error_input = torch.randn(2, 9)\n",
        "\n",
        "  error_output = model(error_input)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaMOfnP_Isfa"
      },
      "source": [
        "# Your Turn\n",
        "\n",
        "Try creating your own model. Use several layers and make sure to include activations in your `forward()` declaration.\n",
        "\n",
        "Test your model on a dummy input to see if it outputs what you expect.\n",
        "\n",
        "<br>\n",
        "\n",
        "Documentation for pytorch layers is found [here](https://docs.pytorch.org/docs/stable/nn.html) and activation functions [here](https://docs.pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANf9sTzOIr_L"
      },
      "outputs": [],
      "source": [
        "# your model here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
